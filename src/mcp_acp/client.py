"""ACP client wrapper for OpenShift CLI operations."""

import asyncio
import json
import re
import subprocess
import secrets
import shlex
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional, Union

import yaml

from utils.pylogger import get_python_logger
from mcp_acp.settings import ClustersConfig, Settings, load_clusters_config, load_settings

# Initialize structured logger
logger = get_python_logger()


class ACPClient:
    """Client for interacting with ACP via OpenShift CLI.

    Attributes:
        settings: Global settings instance
        clusters_config: Cluster configuration instance
        config: Raw cluster configuration (for backward compatibility)
    """

    # Security constants
    ALLOWED_RESOURCE_TYPES = {"agenticsession", "pods", "event"}  # Whitelist

    def __init__(self, config_path: Optional[str] = None, settings: Optional[Settings] = None):
        """Initialize ACP client.

        Args:
            config_path: Path to clusters.yaml config file (deprecated, use settings)
            settings: Settings instance. If not provided, loads default settings.
        """
        # Load or use provided settings
        self.settings = settings or load_settings()

        # Override config path if provided (for backward compatibility)
        if config_path:
            self.settings.config_path = Path(config_path)

        # Load cluster configuration
        try:
            self.clusters_config = load_clusters_config(self.settings)
        except Exception as e:
            logger.error("cluster_config_load_failed", error=str(e))
            raise

        # Backward compatibility: expose raw config
        self.config = {
            "clusters": {
                name: {
                    "server": cluster.server,
                    "default_project": cluster.default_project,
                    "description": cluster.description,
                }
                for name, cluster in self.clusters_config.clusters.items()
            },
            "default_cluster": self.clusters_config.default_cluster,
        }
        self.config_path = str(self.settings.config_path)

        logger.info(
            "acp_client_initialized",
            clusters=list(self.clusters_config.clusters.keys()),
            default_cluster=self.clusters_config.default_cluster,
        )

    # Note: _load_config and _validate_config removed - now handled by Pydantic settings

    def _validate_input(self, value: str, field_name: str, max_length: int = 253) -> None:
        """Validate input to prevent injection attacks.

        Args:
            value: Value to validate
            field_name: Field name for error messages
            max_length: Maximum allowed length

        Raises:
            ValueError: If validation fails
        """
        if not isinstance(value, str):
            raise ValueError(f"{field_name} must be a string")
        if len(value) > max_length:
            raise ValueError(f"{field_name} exceeds maximum length of {max_length}")
        # Validate Kubernetes naming conventions (DNS-1123 subdomain)
        if not re.match(r'^[a-z0-9]([-a-z0-9]*[a-z0-9])?$', value):
            raise ValueError(f"{field_name} contains invalid characters. Must match: ^[a-z0-9]([-a-z0-9]*[a-z0-9])?$")

    async def _run_oc_command(
        self,
        args: List[str],
        capture_output: bool = True,
        parse_json: bool = False,
        timeout: Optional[int] = None,
    ) -> Union[subprocess.CompletedProcess, Dict[str, Any]]:
        """Run an oc command asynchronously with security controls.

        Args:
            args: Command arguments (will be validated)
            capture_output: Whether to capture stdout/stderr
            parse_json: If True, parse stdout as JSON and return dict
            timeout: Command timeout in seconds (default: MAX_COMMAND_TIMEOUT)

        Returns:
            CompletedProcess result or parsed JSON dict

        Raises:
            asyncio.TimeoutError: If command exceeds timeout
            ValueError: If arguments contain suspicious content
        """
        # Security: Validate arguments don't contain shell metacharacters
        for arg in args:
            if not isinstance(arg, str):
                raise ValueError(f"All arguments must be strings, got {type(arg)}")
            # Detect potential command injection
            if any(char in arg for char in [';', '|', '&', '$', '`', '\n', '\r']):
                raise ValueError(f"Argument contains suspicious characters: {arg}")

        cmd = ["oc"] + args
        effective_timeout = timeout or self.MAX_COMMAND_TIMEOUT

        if capture_output:
            try:
                process = await asyncio.create_subprocess_exec(
                    *cmd,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE,
                    # Security: Prevent shell injection
                )
                stdout, stderr = await asyncio.wait_for(
                    process.communicate(),
                    timeout=effective_timeout
                )
                result = subprocess.CompletedProcess(
                    args=cmd,
                    returncode=process.returncode or 0,
                    stdout=stdout,
                    stderr=stderr,
                )

                if parse_json and result.returncode == 0:
                    try:
                        return json.loads(result.stdout.decode())
                    except json.JSONDecodeError as e:
                        raise ValueError(f"Failed to parse JSON response: {e}")

                return result
            except asyncio.TimeoutError:
                # Kill the process if it times out
                try:
                    process.kill()
                    await process.wait()
                except:
                    pass
                raise asyncio.TimeoutError(f"Command timed out after {effective_timeout}s")
        else:
            # For non-captured output, use subprocess.run with timeout
            try:
                result = await asyncio.wait_for(
                    asyncio.to_thread(subprocess.run, cmd, capture_output=False, timeout=effective_timeout),
                    timeout=effective_timeout + 5  # Extra buffer
                )
                return result
            except subprocess.TimeoutExpired:
                raise asyncio.TimeoutError(f"Command timed out after {effective_timeout}s")

    async def _get_resource_json(
        self, resource_type: str, name: str, namespace: str
    ) -> Dict[str, Any]:
        """Get a Kubernetes resource as JSON dict.

        Args:
            resource_type: Resource type (e.g., 'agenticsession')
            name: Resource name
            namespace: Namespace

        Returns:
            Resource as JSON dict

        Raises:
            ValueError: If inputs are invalid
            Exception: If resource not found or command fails
        """
        # Security: Validate inputs
        if resource_type not in self.ALLOWED_RESOURCE_TYPES:
            raise ValueError(f"Resource type '{resource_type}' not allowed")
        self._validate_input(name, "resource name")
        self._validate_input(namespace, "namespace")

        result = await self._run_oc_command(
            ["get", resource_type, name, "-n", namespace, "-o", "json"]
        )

        if result.returncode != 0:
            raise Exception(
                f"Failed to get {resource_type} '{name}': {result.stderr.decode()}"
            )

        return json.loads(result.stdout.decode())

    async def _list_resources_json(
        self, resource_type: str, namespace: str, selector: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """List Kubernetes resources as JSON dicts.

        Args:
            resource_type: Resource type (e.g., 'agenticsession')
            namespace: Namespace
            selector: Optional label selector

        Returns:
            List of resources as JSON dicts

        Raises:
            ValueError: If inputs are invalid
            Exception: If command fails
        """
        # Security: Validate inputs
        if resource_type not in self.ALLOWED_RESOURCE_TYPES:
            raise ValueError(f"Resource type '{resource_type}' not allowed")
        self._validate_input(namespace, "namespace")
        if selector and not re.match(r'^[a-zA-Z0-9=,_-]+$', selector):
            raise ValueError(f"Invalid label selector format: {selector}")

        args = ["get", resource_type, "-n", namespace, "-o", "json"]
        if selector:
            args.extend(["-l", selector])

        result = await self._run_oc_command(args)

        if result.returncode != 0:
            raise Exception(
                f"Failed to list {resource_type}: {result.stderr.decode()}"
            )

        data = json.loads(result.stdout.decode())
        return data.get("items", [])

    async def _validate_session_for_dry_run(
        self, project: str, session: str, operation: str
    ) -> Dict[str, Any]:
        """Validate session exists for dry-run and return session info.

        Args:
            project: Project/namespace name
            session: Session name
            operation: Operation name for message (e.g., "delete", "restart")

        Returns:
            Dict with dry_run response including session_info if found
        """
        try:
            session_data = await self._get_resource_json(
                "agenticsession", session, project
            )

            return {
                "dry_run": True,
                "success": True,
                "message": f"Would {operation} session '{session}' in project '{project}'",
                "session_info": {
                    "name": session_data.get("metadata", {}).get("name"),
                    "status": session_data.get("status", {}).get("phase"),
                    "created": session_data.get("metadata", {}).get(
                        "creationTimestamp"
                    ),
                    "stopped_at": session_data.get("status", {}).get("stoppedAt"),
                },
            }
        except Exception as e:
            return {
                "dry_run": True,
                "success": False,
                "message": f"Session '{session}' not found in project '{project}'",
            }

    async def _bulk_operation(
        self,
        project: str,
        sessions: List[str],
        operation_fn: Callable,
        success_key: str,
        dry_run: bool = False,
    ) -> Dict[str, Any]:
        """Generic bulk operation handler.

        Args:
            project: Project/namespace name
            sessions: List of session names
            operation_fn: Async function to call for each session
            success_key: Key name for successful operations in response
            dry_run: Preview mode

        Returns:
            Standardized bulk operation response
        """
        success = []
        failed = []
        dry_run_info = {"would_execute": [], "skipped": []}

        for session in sessions:
            result = await operation_fn(project, session, dry_run=dry_run)

            if dry_run:
                if result.get("success", True):
                    dry_run_info["would_execute"].append(
                        {
                            "session": session,
                            "info": result.get("session_info"),
                        }
                    )
                else:
                    dry_run_info["skipped"].append(
                        {
                            "session": session,
                            "reason": result.get("message"),
                        }
                    )
            else:
                if result.get(success_key, result.get("success")):
                    success.append(session)
                else:
                    failed.append(
                        {"session": session, "error": result.get("message")}
                    )

        response = {success_key: success, "failed": failed}
        if dry_run:
            response["dry_run"] = True
            response["dry_run_info"] = dry_run_info

        return response

    async def list_sessions(
        self,
        project: str,
        status: Optional[str] = None,
        has_display_name: Optional[bool] = None,
        older_than: Optional[str] = None,
        sort_by: Optional[str] = None,
        limit: Optional[int] = None,
    ) -> Dict[str, Any]:
        """List sessions with enhanced filtering.

        Args:
            project: Project/namespace name
            status: Filter by status (running, stopped, creating, failed)
            has_display_name: Filter by display name presence
            older_than: Filter by age (e.g., "7d", "24h")
            sort_by: Sort field (created, stopped, name)
            limit: Maximum results

        Returns:
            Dict with sessions list and metadata
        """
        sessions = await self._list_resources_json("agenticsession", project)

        # Build filter predicates
        filters = []
        filters_applied = {}

        if status:
            filters.append(
                lambda s: s.get("status", {}).get("phase", "").lower()
                == status.lower()
            )
            filters_applied["status"] = status

        if has_display_name is not None:
            filters.append(
                lambda s: bool(s.get("spec", {}).get("displayName"))
                == has_display_name
            )
            filters_applied["has_display_name"] = has_display_name

        if older_than:
            cutoff_time = self._parse_time_delta(older_than)
            filters.append(
                lambda s: self._is_older_than(
                    s.get("metadata", {}).get("creationTimestamp"), cutoff_time
                )
            )
            filters_applied["older_than"] = older_than

        # Single-pass filter
        filtered = [s for s in sessions if all(f(s) for f in filters)]

        # Sort
        if sort_by:
            filtered = self._sort_sessions(filtered, sort_by)
            filters_applied["sort_by"] = sort_by

        # Limit
        if limit and limit > 0:
            filtered = filtered[:limit]
            filters_applied["limit"] = limit

        return {
            "sessions": filtered,
            "total": len(filtered),
            "filters_applied": filters_applied,
        }

    def _sort_sessions(self, sessions: List[Dict], sort_by: str) -> List[Dict]:
        """Sort sessions by field.

        Args:
            sessions: List of session dicts
            sort_by: Sort field (created, stopped, name)

        Returns:
            Sorted list
        """
        sort_keys = {
            "created": lambda s: s.get("metadata", {}).get("creationTimestamp", ""),
            "stopped": lambda s: s.get("status", {}).get("stoppedAt", ""),
            "name": lambda s: s.get("metadata", {}).get("name", ""),
        }

        key_fn = sort_keys.get(sort_by)
        if key_fn:
            return sorted(sessions, key=key_fn, reverse=(sort_by != "name"))
        return sessions

    def _parse_time_delta(self, time_str: str) -> datetime:
        """Parse time delta string (e.g., '7d', '24h') to datetime.

        Args:
            time_str: Time delta string

        Returns:
            Datetime representing the cutoff time
        """
        match = re.match(r"(\d+)([dhm])", time_str.lower())
        if not match:
            raise ValueError(
                f"Invalid time format: {time_str}. Use format like '7d', '24h', '30m'"
            )

        value, unit = int(match.group(1)), match.group(2)
        now = datetime.utcnow()

        if unit == "d":
            return now - timedelta(days=value)
        elif unit == "h":
            return now - timedelta(hours=value)
        elif unit == "m":
            return now - timedelta(minutes=value)

        raise ValueError(f"Unknown time unit: {unit}")

    def _is_older_than(self, timestamp_str: Optional[str], cutoff: datetime) -> bool:
        """Check if timestamp is older than cutoff.

        Args:
            timestamp_str: ISO format timestamp string
            cutoff: Cutoff datetime

        Returns:
            True if older than cutoff
        """
        if not timestamp_str:
            return False

        # Parse ISO format timestamp
        timestamp = datetime.fromisoformat(timestamp_str.replace("Z", "+00:00"))
        return timestamp.replace(tzinfo=None) < cutoff

    async def delete_session(
        self, project: str, session: str, dry_run: bool = False
    ) -> Dict[str, Any]:
        """Delete a session.

        Args:
            project: Project/namespace name
            session: Session name
            dry_run: Preview without deleting

        Returns:
            Dict with deletion status
        """
        if dry_run:
            return await self._validate_session_for_dry_run(project, session, "delete")

        result = await self._run_oc_command(
            ["delete", "agenticsession", session, "-n", project]
        )

        if result.returncode != 0:
            return {
                "deleted": False,
                "message": f"Failed to delete session: {result.stderr.decode()}",
            }

        return {
            "deleted": True,
            "message": f"Successfully deleted session '{session}' from project '{project}'",
        }

    async def restart_session(
        self, project: str, session: str, dry_run: bool = False
    ) -> Dict[str, Any]:
        """Restart a stopped session.

        Args:
            project: Project/namespace name
            session: Session name
            dry_run: Preview without restarting

        Returns:
            Dict with restart status
        """
        try:
            session_data = await self._get_resource_json(
                "agenticsession", session, project
            )
            current_status = session_data.get("status", {}).get("phase", "unknown")

            if dry_run:
                return {
                    "status": current_status,
                    "dry_run": True,
                    "success": True,
                    "message": f"Would restart session '{session}' (current status: {current_status})",
                    "session_info": {
                        "name": session_data.get("metadata", {}).get("name"),
                        "current_status": current_status,
                        "stopped_at": session_data.get("status", {}).get("stoppedAt"),
                    },
                }

            # Restart by patching the stopped field to false
            patch = {"spec": {"stopped": False}}
            result = await self._run_oc_command(
                [
                    "patch",
                    "agenticsession",
                    session,
                    "-n",
                    project,
                    "--type=merge",
                    "-p",
                    json.dumps(patch),
                ]
            )

            if result.returncode != 0:
                return {
                    "status": "error",
                    "message": f"Failed to restart session: {result.stderr.decode()}",
                }

            return {
                "status": "restarting",
                "message": f"Successfully restarted session '{session}' in project '{project}'",
            }
        except Exception as e:
            return {"status": "error", "message": str(e)}

    async def bulk_delete_sessions(
        self, project: str, sessions: List[str], dry_run: bool = False
    ) -> Dict[str, Any]:
        """Delete multiple sessions.

        Args:
            project: Project/namespace name
            sessions: List of session names
            dry_run: Preview without deleting

        Returns:
            Dict with deletion results
        """
        return await self._bulk_operation(
            project, sessions, self.delete_session, "deleted", dry_run
        )

    async def bulk_stop_sessions(
        self, project: str, sessions: List[str], dry_run: bool = False
    ) -> Dict[str, Any]:
        """Stop multiple running sessions.

        Args:
            project: Project/namespace name
            sessions: List of session names
            dry_run: Preview without stopping

        Returns:
            Dict with stop results
        """

        async def stop_session(
            project: str, session: str, dry_run: bool = False
        ) -> Dict[str, Any]:
            """Internal stop session helper."""
            try:
                session_data = await self._get_resource_json(
                    "agenticsession", session, project
                )
                current_status = session_data.get("status", {}).get("phase")

                if dry_run:
                    return {
                        "dry_run": True,
                        "success": current_status == "running",
                        "message": f"Session status: {current_status}",
                        "session_info": {
                            "name": session,
                            "status": current_status,
                        },
                    }

                # Stop the session
                patch = {"spec": {"stopped": True}}
                result = await self._run_oc_command(
                    [
                        "patch",
                        "agenticsession",
                        session,
                        "-n",
                        project,
                        "--type=merge",
                        "-p",
                        json.dumps(patch),
                    ]
                )

                if result.returncode == 0:
                    return {"stopped": True, "message": "Success"}
                else:
                    return {
                        "stopped": False,
                        "message": result.stderr.decode(),
                    }
            except Exception as e:
                return {"stopped": False, "success": False, "message": str(e)}

        return await self._bulk_operation(
            project, sessions, stop_session, "stopped", dry_run
        )

    async def get_session_logs(
        self,
        project: str,
        session: str,
        container: Optional[str] = None,
        tail_lines: Optional[int] = None,
    ) -> Dict[str, Any]:
        """Get logs for a session.

        Args:
            project: Project/namespace name
            session: Session name
            container: Container name (optional)
            tail_lines: Number of lines to retrieve

        Returns:
            Dict with logs
        """
        # Security: Validate inputs
        try:
            self._validate_input(project, "project")
            self._validate_input(session, "session")
            if container:
                # Container names have slightly different naming rules
                if not re.match(r'^[a-z0-9]([-a-z0-9]*[a-z0-9])?$', container):
                    raise ValueError(f"Invalid container name: {container}")
            # Security: Limit tail_lines to prevent DoS
            if tail_lines and (tail_lines < 1 or tail_lines > self.MAX_LOG_LINES):
                raise ValueError(f"tail_lines must be between 1 and {self.MAX_LOG_LINES}")

            # Find the pod for this session
            pods = await self._list_resources_json(
                "pods", project, selector=f"agenticsession={session}"
            )

            if not pods:
                return {"logs": "", "error": f"No pods found for session '{session}'"}

            pod_name = pods[0].get("metadata", {}).get("name")

            # Build logs command
            logs_args = ["logs", pod_name, "-n", project]
            if container:
                logs_args.extend(["-c", container])
            if tail_lines:
                logs_args.extend(["--tail", str(tail_lines)])
            else:
                # Default limit to prevent memory exhaustion
                logs_args.extend(["--tail", str(1000)])

            result = await self._run_oc_command(logs_args)

            if result.returncode != 0:
                return {
                    "logs": "",
                    "error": f"Failed to retrieve logs: {result.stderr.decode()}",
                }

            return {
                "logs": result.stdout.decode(),
                "container": container or "default",
                "lines": len(result.stdout.decode().split("\n")),
            }
        except ValueError as e:
            return {"logs": "", "error": str(e)}
        except Exception as e:
            return {"logs": "", "error": f"Unexpected error: {str(e)}"}

    def list_clusters(self) -> Dict[str, Any]:
        """List configured clusters.

        Returns:
            Dict with clusters list
        """
        clusters = []
        config = self.config
        default_cluster = config.get("default_cluster")

        for name, cluster_config in config.get("clusters", {}).items():
            clusters.append(
                {
                    "name": name,
                    "server": cluster_config.get("server"),
                    "description": cluster_config.get("description", ""),
                    "default_project": cluster_config.get("default_project"),
                    "is_default": name == default_cluster,
                }
            )

        return {"clusters": clusters, "default_cluster": default_cluster}

    async def whoami(self) -> Dict[str, Any]:
        """Get current user and cluster information.

        Returns:
            Dict with user info
        """
        # Get current user
        user_result = await self._run_oc_command(["whoami"])
        user = (
            user_result.stdout.decode().strip()
            if user_result.returncode == 0
            else "unknown"
        )

        # Get current server
        server_result = await self._run_oc_command(["whoami", "--show-server"])
        server = (
            server_result.stdout.decode().strip()
            if server_result.returncode == 0
            else "unknown"
        )

        # Get current project
        project_result = await self._run_oc_command(["project", "-q"])
        project = (
            project_result.stdout.decode().strip()
            if project_result.returncode == 0
            else "unknown"
        )

        # Get token info
        token_result = await self._run_oc_command(["whoami", "-t"])
        token_valid = token_result.returncode == 0

        # Try to get token expiry (if available)
        token_expires = None
        if token_valid:
            # Get token and decode to check expiry
            token = token_result.stdout.decode().strip()
            try:
                # Try to get token info from oc
                token_info_result = await self._run_oc_command(["whoami", "--show-token"])
                if token_info_result.returncode == 0:
                    # Note: OpenShift doesn't provide expiry via CLI easily
                    # This is a placeholder for future enhancement
                    token_expires = None
            except:
                pass

        # Get current cluster name (if available from config)
        cluster = "unknown"
        cluster_config_data = None
        for name, cluster_config in self.config.get("clusters", {}).items():
            if cluster_config.get("server") == server:
                cluster = name
                cluster_config_data = cluster_config
                break

        # Prefer default_project from config over current oc project
        # This ensures we use the configured project even if oc is set to a different one
        if cluster_config_data and cluster_config_data.get("default_project"):
            project = cluster_config_data.get("default_project")

        return {
            "user": user,
            "cluster": cluster,
            "server": server,
            "project": project,
            "token_expires": token_expires,
            "token_valid": token_valid,
            "authenticated": user != "unknown" and server != "unknown",
        }

    # P2 Feature: Clone Session
    async def clone_session(
        self, project: str, source_session: str, new_display_name: str, dry_run: bool = False
    ) -> Dict[str, Any]:
        """Clone a session with its configuration.

        Args:
            project: Project/namespace name
            source_session: Source session name to clone
            new_display_name: Display name for new session
            dry_run: Preview without creating

        Returns:
            Dict with cloned session info
        """
        try:
            # Get source session
            source_data = await self._get_resource_json(
                "agenticsession", source_session, project
            )

            if dry_run:
                return {
                    "dry_run": True,
                    "success": True,
                    "message": f"Would clone session '{source_session}' with display name '{new_display_name}'",
                    "source_info": {
                        "name": source_data.get("metadata", {}).get("name"),
                        "display_name": source_data.get("spec", {}).get("displayName"),
                        "repos": source_data.get("spec", {}).get("repos", []),
                        "workflow": source_data.get("spec", {}).get("workflow"),
                    },
                }

            # Create new session from source spec
            new_spec = source_data.get("spec", {}).copy()
            new_spec["displayName"] = new_display_name
            new_spec["stopped"] = False  # Start new session as running

            # Create session manifest
            manifest = {
                "apiVersion": "agenticplatform.io/v1",
                "kind": "AgenticSession",
                "metadata": {
                    "generateName": f"{source_session}-clone-",
                    "namespace": project,
                },
                "spec": new_spec,
            }

            # Apply manifest using secure temporary file
            import tempfile
            import os
            # Security: Use secure temp file with proper permissions (0600)
            fd, manifest_file = tempfile.mkstemp(suffix='.yaml', prefix=f'acp-clone-{secrets.token_hex(8)}-')
            try:
                # Write to file descriptor with secure permissions
                with os.fdopen(fd, 'w') as f:
                    yaml.dump(manifest, f)

                result = await self._run_oc_command(
                    ["create", "-f", manifest_file, "-o", "json"]
                )

                if result.returncode != 0:
                    return {
                        "cloned": False,
                        "message": f"Failed to clone session: {result.stderr.decode()}",
                    }

                created_data = json.loads(result.stdout.decode())
                new_session_name = created_data.get("metadata", {}).get("name")

                return {
                    "cloned": True,
                    "session": new_session_name,
                    "message": f"Successfully cloned session '{source_session}' to '{new_session_name}'",
                }
            finally:
                # Ensure cleanup even if operation fails
                try:
                    os.unlink(manifest_file)
                except OSError:
                    pass

        except Exception as e:
            return {"cloned": False, "message": str(e)}

    # P2 Feature: Get Session Transcript
    async def get_session_transcript(
        self, project: str, session: str, format: str = "json"
    ) -> Dict[str, Any]:
        """Get session transcript/conversation history.

        Args:
            project: Project/namespace name
            session: Session name
            format: Output format ("json" or "markdown")

        Returns:
            Dict with transcript data
        """
        try:
            session_data = await self._get_resource_json(
                "agenticsession", session, project
            )

            # Get events which contain the conversation
            events = await self._list_resources_json(
                "event", project, selector=f"involvedObject.name={session}"
            )

            # Extract transcript from session status if available
            transcript_data = session_data.get("status", {}).get("transcript") or []

            if format == "markdown":
                # Convert to markdown format
                markdown = f"# Session Transcript: {session}\n\n"
                for idx, entry in enumerate(transcript_data):
                    role = entry.get("role", "unknown")
                    content = entry.get("content", "")
                    timestamp = entry.get("timestamp", "")
                    markdown += f"## Message {idx + 1} - {role}\n"
                    if timestamp:
                        markdown += f"*{timestamp}*\n\n"
                    markdown += f"{content}\n\n"
                    markdown += "---\n\n"

                return {
                    "transcript": markdown,
                    "format": "markdown",
                    "message_count": len(transcript_data),
                }
            else:
                # Return as JSON
                return {
                    "transcript": transcript_data,
                    "format": "json",
                    "message_count": len(transcript_data),
                }

        except Exception as e:
            return {"transcript": None, "error": str(e)}

    # P2 Feature: Update Session
    async def update_session(
        self,
        project: str,
        session: str,
        display_name: Optional[str] = None,
        timeout: Optional[int] = None,
        dry_run: bool = False,
    ) -> Dict[str, Any]:
        """Update session metadata.

        Args:
            project: Project/namespace name
            session: Session name
            display_name: New display name
            timeout: New timeout in seconds
            dry_run: Preview without updating

        Returns:
            Dict with update status
        """
        try:
            session_data = await self._get_resource_json(
                "agenticsession", session, project
            )

            if dry_run:
                updates = {}
                if display_name:
                    updates["displayName"] = display_name
                if timeout:
                    updates["timeout"] = timeout

                return {
                    "dry_run": True,
                    "success": True,
                    "message": f"Would update session '{session}'",
                    "updates": updates,
                    "current": {
                        "displayName": session_data.get("spec", {}).get("displayName"),
                        "timeout": session_data.get("spec", {}).get("timeout"),
                    },
                }

            # Build patch
            patch = {"spec": {}}
            if display_name:
                patch["spec"]["displayName"] = display_name
            if timeout:
                patch["spec"]["timeout"] = timeout

            if not patch["spec"]:
                return {"updated": False, "message": "No updates specified"}

            result = await self._run_oc_command(
                [
                    "patch",
                    "agenticsession",
                    session,
                    "-n",
                    project,
                    "--type=merge",
                    "-p",
                    json.dumps(patch),
                    "-o",
                    "json",
                ]
            )

            if result.returncode != 0:
                return {
                    "updated": False,
                    "message": f"Failed to update session: {result.stderr.decode()}",
                }

            updated_data = json.loads(result.stdout.decode())

            return {
                "updated": True,
                "session": updated_data,
                "message": f"Successfully updated session '{session}'",
            }

        except Exception as e:
            return {"updated": False, "message": str(e)}

    # P2 Feature: Export Session
    async def export_session(
        self, project: str, session: str
    ) -> Dict[str, Any]:
        """Export session configuration and transcript.

        Args:
            project: Project/namespace name
            session: Session name

        Returns:
            Dict with exported session data
        """
        try:
            session_data = await self._get_resource_json(
                "agenticsession", session, project
            )

            # Get transcript
            transcript_result = await self.get_session_transcript(
                project, session, format="json"
            )

            export_data = {
                "config": {
                    "name": session_data.get("metadata", {}).get("name"),
                    "displayName": session_data.get("spec", {}).get("displayName"),
                    "repos": session_data.get("spec", {}).get("repos", []),
                    "workflow": session_data.get("spec", {}).get("workflow"),
                    "llmConfig": session_data.get("spec", {}).get("llmConfig", {}),
                },
                "transcript": transcript_result.get("transcript", []),
                "metadata": {
                    "created": session_data.get("metadata", {}).get("creationTimestamp"),
                    "status": session_data.get("status", {}).get("phase"),
                    "stoppedAt": session_data.get("status", {}).get("stoppedAt"),
                    "messageCount": transcript_result.get("message_count", 0),
                },
            }

            return {
                "exported": True,
                "data": export_data,
                "message": f"Successfully exported session '{session}'",
            }

        except Exception as e:
            return {"exported": False, "error": str(e)}

    # P3 Feature: Get Session Metrics
    async def get_session_metrics(
        self, project: str, session: str
    ) -> Dict[str, Any]:
        """Get session metrics and statistics.

        Args:
            project: Project/namespace name
            session: Session name

        Returns:
            Dict with session metrics
        """
        try:
            session_data = await self._get_resource_json(
                "agenticsession", session, project
            )

            # Get transcript for analysis
            transcript_result = await self.get_session_transcript(
                project, session, format="json"
            )
            transcript = transcript_result.get("transcript") or []

            # Calculate metrics
            token_count = 0
            message_count = len(transcript) if transcript else 0
            tool_calls = {}

            for entry in transcript:
                # Count tokens (approximate)
                content = entry.get("content", "")
                token_count += len(content.split()) * 1.3  # Rough estimate

                # Count tool calls
                if "tool_calls" in entry:
                    for tool_call in entry.get("tool_calls", []):
                        tool_name = tool_call.get("name", "unknown")
                        tool_calls[tool_name] = tool_calls.get(tool_name, 0) + 1

            # Calculate duration
            created = session_data.get("metadata", {}).get("creationTimestamp")
            stopped = session_data.get("status", {}).get("stoppedAt")

            duration_seconds = 0
            if created and stopped:
                try:
                    from datetime import datetime
                    created_dt = datetime.fromisoformat(created.replace("Z", "+00:00"))
                    stopped_dt = datetime.fromisoformat(stopped.replace("Z", "+00:00"))
                    duration_seconds = int((stopped_dt - created_dt).total_seconds())
                except:
                    pass

            return {
                "token_count": int(token_count),
                "duration_seconds": duration_seconds,
                "tool_calls": tool_calls,
                "message_count": message_count,
                "status": session_data.get("status", {}).get("phase"),
            }

        except Exception as e:
            return {"error": str(e)}

    # P3 Feature: List Workflows
    async def list_workflows(
        self, repo_url: Optional[str] = None
    ) -> Dict[str, Any]:
        """List available workflows from repository.

        Args:
            repo_url: Repository URL (defaults to ootb-ambient-workflows)

        Returns:
            Dict with workflows list
        """
        if not repo_url:
            repo_url = "https://github.com/ambient-code/ootb-ambient-workflows"

        # Security: Validate repo URL format
        if not isinstance(repo_url, str):
            return {"workflows": [], "error": "Repository URL must be a string"}
        if not (repo_url.startswith("https://") or repo_url.startswith("http://")):
            return {"workflows": [], "error": "Repository URL must use http:// or https://"}
        # Prevent command injection through URL
        if any(char in repo_url for char in [';', '|', '&', '$', '`', '\n', '\r', ' ']):
            return {"workflows": [], "error": "Invalid characters in repository URL"}

        try:
            # Clone repo to temp directory
            import tempfile
            import shutil

            # Security: Use secure temp directory with random name
            temp_dir = tempfile.mkdtemp(prefix=f'acp-workflows-{secrets.token_hex(8)}-')

            try:
                # Clone the repo using secure subprocess
                process = await asyncio.create_subprocess_exec(
                    "git", "clone", "--depth", "1", "--", repo_url, temp_dir,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE,
                )
                stdout, stderr = await asyncio.wait_for(
                    process.communicate(),
                    timeout=60  # 60 second timeout for git clone
                )

                if process.returncode != 0:
                    return {
                        "workflows": [],
                        "error": f"Failed to clone repository: {stderr.decode()}",
                    }

                # Find workflow files
                workflows = []
                workflows_dir = Path(temp_dir) / "workflows"

                if workflows_dir.exists():
                    # Limit to prevent DoS
                    file_count = 0
                    max_files = 100
                    for workflow_file in workflows_dir.glob("**/*.yaml"):
                        if file_count >= max_files:
                            break
                        file_count += 1

                        # Security: Validate file is within expected directory
                        try:
                            workflow_file.resolve().relative_to(workflows_dir.resolve())
                        except ValueError:
                            continue  # Skip files outside workflows directory

                        # Read workflow to get metadata
                        try:
                            with open(workflow_file, "r") as f:
                                workflow_data = yaml.safe_load(f)
                                if not isinstance(workflow_data, dict):
                                    workflow_data = {}

                            workflows.append({
                                "name": workflow_file.stem,
                                "path": str(workflow_file.relative_to(workflows_dir)),
                                "description": workflow_data.get("description", "") if isinstance(workflow_data.get("description"), str) else "",
                            })
                        except (yaml.YAMLError, OSError):
                            # Skip invalid workflow files
                            continue

                return {
                    "workflows": workflows,
                    "repo_url": repo_url,
                    "count": len(workflows),
                }

            finally:
                # Clean up temp directory securely
                try:
                    shutil.rmtree(temp_dir, ignore_errors=True)
                except:
                    pass

        except asyncio.TimeoutError:
            return {"workflows": [], "error": "Repository clone timed out"}
        except Exception as e:
            return {"workflows": [], "error": f"Unexpected error: {str(e)}"}

    # P3 Feature: Create Session from Template
    async def create_session_from_template(
        self,
        project: str,
        template: str,
        display_name: str,
        repos: Optional[List[str]] = None,
        dry_run: bool = False,
    ) -> Dict[str, Any]:
        """Create session from predefined template.

        Args:
            project: Project/namespace name
            template: Template name (triage, bugfix, feature, exploration)
            display_name: Display name for session
            repos: Optional list of repository URLs
            dry_run: Preview without creating

        Returns:
            Dict with session creation status
        """
        # Define templates
        templates = {
            "triage": {
                "workflow": "triage",
                "llmConfig": {"model": "claude-sonnet-4", "temperature": 0.7},
                "description": "Triage and analyze issues",
            },
            "bugfix": {
                "workflow": "bugfix",
                "llmConfig": {"model": "claude-sonnet-4", "temperature": 0.3},
                "description": "Fix bugs and issues",
            },
            "feature": {
                "workflow": "feature-development",
                "llmConfig": {"model": "claude-sonnet-4", "temperature": 0.5},
                "description": "Develop new features",
            },
            "exploration": {
                "workflow": "codebase-exploration",
                "llmConfig": {"model": "claude-sonnet-4", "temperature": 0.8},
                "description": "Explore codebase",
            },
        }

        if template not in templates:
            return {
                "created": False,
                "message": f"Unknown template: {template}. Available: {', '.join(templates.keys())}",
            }

        template_config = templates[template]

        if dry_run:
            return {
                "dry_run": True,
                "success": True,
                "message": f"Would create session from template '{template}'",
                "template_config": template_config,
                "display_name": display_name,
                "repos": repos or [],
            }

        try:
            # Create session manifest
            manifest = {
                "apiVersion": "agenticplatform.io/v1",
                "kind": "AgenticSession",
                "metadata": {
                    "generateName": f"{template}-",
                    "namespace": project,
                },
                "spec": {
                    "displayName": display_name,
                    "workflow": template_config["workflow"],
                    "llmConfig": template_config["llmConfig"],
                    "repos": repos or [],
                },
            }

            # Apply manifest using secure temporary file
            import tempfile
            import os
            # Security: Use secure temp file with proper permissions (0600)
            fd, manifest_file = tempfile.mkstemp(suffix='.yaml', prefix=f'acp-template-{secrets.token_hex(8)}-')
            try:
                # Write to file descriptor with secure permissions
                with os.fdopen(fd, 'w') as f:
                    yaml.dump(manifest, f)

                result = await self._run_oc_command(
                    ["create", "-f", manifest_file, "-o", "json"]
                )

                if result.returncode != 0:
                    return {
                        "created": False,
                        "message": f"Failed to create session: {result.stderr.decode()}",
                    }

                created_data = json.loads(result.stdout.decode())
                session_name = created_data.get("metadata", {}).get("name")

                return {
                    "created": True,
                    "session": session_name,
                    "message": f"Successfully created session '{session_name}' from template '{template}'",
                }
            finally:
                # Ensure cleanup even if operation fails
                try:
                    os.unlink(manifest_file)
                except OSError:
                    pass

        except Exception as e:
            return {"created": False, "message": str(e)}

    # Auth Feature: Login
    async def login(
        self, cluster: str, web: bool = True, token: Optional[str] = None
    ) -> Dict[str, Any]:
        """Authenticate to OpenShift cluster.

        Args:
            cluster: Cluster alias name or server URL
            web: Use web login flow
            token: Direct token authentication

        Returns:
            Dict with login status
        """
        # Look up cluster in config
        server = cluster
        if cluster in self.config.get("clusters", {}):
            server = self.config["clusters"][cluster]["server"]

        try:
            if token:
                # Token-based login
                result = await self._run_oc_command(
                    ["login", "--token", token, "--server", server],
                    capture_output=False,
                )
            elif web:
                # Web-based login
                result = await self._run_oc_command(
                    ["login", "--web", "--server", server],
                    capture_output=False,
                )
            else:
                return {
                    "authenticated": False,
                    "message": "Either 'web' or 'token' must be provided",
                }

            if result.returncode != 0:
                return {
                    "authenticated": False,
                    "message": "Login failed",
                }

            # Get user info after login
            whoami_result = await self.whoami()

            return {
                "authenticated": True,
                "user": whoami_result.get("user"),
                "cluster": cluster,
                "server": server,
                "message": f"Successfully logged in to {cluster}",
            }

        except Exception as e:
            return {"authenticated": False, "message": str(e)}

    # Auth Feature: Switch Cluster
    async def switch_cluster(self, cluster: str) -> Dict[str, Any]:
        """Switch to a different cluster context.

        Args:
            cluster: Cluster alias name

        Returns:
            Dict with switch status
        """
        if cluster not in self.config.get("clusters", {}):
            return {
                "switched": False,
                "message": f"Unknown cluster: {cluster}. Use acp_list_clusters to see available clusters.",
            }

        cluster_config = self.config["clusters"][cluster]
        server = cluster_config["server"]

        try:
            # Get current context
            current_whoami = await self.whoami()
            previous_cluster = current_whoami.get("cluster", "unknown")

            # Switch context (assumes already authenticated)
            result = await self._run_oc_command(
                ["login", "--server", server],
                capture_output=False,
            )

            if result.returncode != 0:
                return {
                    "switched": False,
                    "message": f"Failed to switch to {cluster}. You may need to login first.",
                }

            # Get new user info
            new_whoami = await self.whoami()

            return {
                "switched": True,
                "previous": previous_cluster,
                "current": cluster,
                "user": new_whoami.get("user"),
                "message": f"Switched from {previous_cluster} to {cluster}",
            }

        except Exception as e:
            return {"switched": False, "message": str(e)}

    # Auth Feature: Add Cluster
    def add_cluster(
        self,
        name: str,
        server: str,
        description: Optional[str] = None,
        default_project: Optional[str] = None,
        set_default: bool = False,
    ) -> Dict[str, Any]:
        """Add a new cluster to configuration.

        Args:
            name: Cluster alias name
            server: Server URL
            description: Optional description
            default_project: Optional default project
            set_default: Set as default cluster

        Returns:
            Dict with add status
        """
        try:
            # Security: Validate inputs
            if not isinstance(name, str) or not re.match(r'^[a-z0-9]([-a-z0-9]*[a-z0-9])?$', name):
                return {"added": False, "message": "Invalid cluster name format"}
            if not isinstance(server, str) or not (server.startswith("https://") or server.startswith("http://")):
                return {"added": False, "message": "Server must be a valid HTTP/HTTPS URL"}
            if description and (not isinstance(description, str) or len(description) > 500):
                return {"added": False, "message": "Description must be a string under 500 characters"}
            if default_project:
                try:
                    self._validate_input(default_project, "default_project")
                except ValueError as e:
                    return {"added": False, "message": str(e)}

            # Update config
            if "clusters" not in self.config:
                self.config["clusters"] = {}

            self.config["clusters"][name] = {
                "server": server,
                "description": description or "",
                "default_project": default_project,
            }

            if set_default:
                self.config["default_cluster"] = name

            # Save config securely
            config_file = Path(self.config_path)
            config_file.parent.mkdir(parents=True, exist_ok=True)

            # Security: Write with restricted permissions
            with open(config_file, "w") as f:
                yaml.dump(self.config, f)
            # Set file permissions to 0600 (owner read/write only)
            import os
            os.chmod(config_file, 0o600)

            return {
                "added": True,
                "cluster": {
                    "name": name,
                    "server": server,
                    "description": description,
                    "default_project": default_project,
                    "is_default": set_default,
                },
                "message": f"Successfully added cluster '{name}'",
            }

        except Exception as e:
            return {"added": False, "message": f"Failed to add cluster: {str(e)}"}
